{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1bf6ade-ff66-456c-b289-b17ea269c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\swapn\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\swapn\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip  install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2f5295-6fcd-458c-a241-c74157c549b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Text Artificial Intelligence (AI) has its roots in ancient times when people imagined machines or statues that could think and act like humans. Philosophers like Aristotle laid the groundwork by studying logic and reasoning.  In the 1950s, scientists began building real machines that could solve problems. In 1956, a group of researchers held a conference at Dartmouth College and officially named the field “Artificial Intelligence.” They believed that machines could learn to think just like humans.  In the 1960s and 70s, AI research made progress. Computers could play games like chess and solve math problems. But soon, people realized that the technology wasn’t advanced enough, and funding was cut. This led to the first \"AI winter,\" a period when interest in AI dropped.  In the 1980s, AI became popular again because of expert systems—programs that could make decisions like a human expert. But these systems were expensive and hard to maintain, which caused another decline in the 1990s.  AI came back strong in the 2000s with the rise of machine learning. Computers started learning from data instead of just following rules. In 1997, IBM's Deep Blue beat the world chess champion. In 2012, deep learning took off when a program called AlexNet beat others in an image recognition contest.  Since then, AI has improved rapidly. Tools like Siri, Google Assistant, and self-driving cars all use AI. In 2016, AlphaGo beat a top human player in the game of Go. In 2020, language models like GPT-3 could write essays, answer questions, and hold conversations.  Today, AI is everywhere—from hospitals and schools to phones and factories. While it brings many benefits, it also raises concerns about jobs, fairness, and safety. That’s why governments and researchers are working on rules to use AI responsibly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words {'most', 'herself', \"he's\", 'just', \"you're\", \"you've\", 'during', 'into', 'themselves', 'up', \"they're\", \"you'd\", 'am', \"we're\", 'whom', 'shan', 'or', 'in', 'while', 'until', 'wouldn', \"i'll\", 'being', \"that'll\", 'any', \"i've\", 'ain', 'my', \"hadn't\", 'each', 'i', 'under', 'have', 'nor', \"it'll\", 'doing', 'has', 'aren', 's', 'other', 've', \"wasn't\", 'haven', 'ours', \"doesn't\", 'from', 'is', \"should've\", 'why', 'his', 'below', \"wouldn't\", 'your', 'if', 'for', 'were', 'he', 'such', 'them', \"they'd\", 'and', 'was', 'hasn', \"mightn't\", \"won't\", 'some', 'few', 'both', 'mustn', 'had', 'hadn', 'it', 'an', 'own', 'wasn', 'too', 'between', \"don't\", 'same', 'needn', 'when', 'here', 'to', \"we'd\", 'having', \"isn't\", 'those', 'these', \"hasn't\", \"shouldn't\", \"weren't\", 'off', 'no', 'ourselves', 'where', 'd', 'their', 'weren', 'what', 'who', 'isn', 'hers', 'only', 'we', 'after', 'll', 't', 'than', 'because', 'but', \"she's\", \"shan't\", 'will', 'by', 'a', \"needn't\", 'mightn', 'yourselves', 'of', \"i'm\", 'yours', 'himself', 'further', 'on', 'can', 'don', \"they've\", 'so', 'theirs', \"aren't\", 'myself', 'y', \"she'd\", 'won', 'that', 'very', 'over', \"didn't\", 'this', 'there', 'with', \"it'd\", 'ma', 'should', 'do', \"we'll\", \"he'd\", 'its', 'all', 'then', \"mustn't\", 'more', 'the', 'm', 'o', \"she'll\", 'shouldn', 'above', \"they'll\", 'itself', 'they', 'her', 'not', 'again', 'didn', \"we've\", 'did', 'about', \"he'll\", 'been', 'before', 'are', 'now', \"couldn't\", 'me', 'through', \"you'll\", 'does', 'him', 'doesn', 'how', \"i'd\", 'couldn', \"it's\", 'down', 'once', 're', 'yourself', 'she', 'against', 'be', 'you', 'at', 'out', 'which', \"haven't\", 'our', 'as'}\n",
      "Total number of Tokens 343\n",
      "Tokens: ['Artificial', 'Intelligence', '(', 'AI', ')', 'has', 'its', 'roots', 'in', 'ancient', 'times', 'when', 'people', 'imagined', 'machines', 'or', 'statues', 'that', 'could', 'think', 'and', 'act', 'like', 'humans', '.', 'Philosophers', 'like', 'Aristotle', 'laid', 'the', 'groundwork', 'by', 'studying', 'logic', 'and', 'reasoning', '.', 'In', 'the', '1950s', ',', 'scientists', 'began', 'building', 'real', 'machines', 'that', 'could', 'solve', 'problems', '.', 'In', '1956', ',', 'a', 'group', 'of', 'researchers', 'held', 'a', 'conference', 'at', 'Dartmouth', 'College', 'and', 'officially', 'named', 'the', 'field', '“', 'Artificial', 'Intelligence.', '”', 'They', 'believed', 'that', 'machines', 'could', 'learn', 'to', 'think', 'just', 'like', 'humans', '.', 'In', 'the', '1960s', 'and', '70s', ',', 'AI', 'research', 'made', 'progress', '.', 'Computers', 'could', 'play', 'games', 'like', 'chess', 'and', 'solve', 'math', 'problems', '.', 'But', 'soon', ',', 'people', 'realized', 'that', 'the', 'technology', 'wasn', '’', 't', 'advanced', 'enough', ',', 'and', 'funding', 'was', 'cut', '.', 'This', 'led', 'to', 'the', 'first', '``', 'AI', 'winter', ',', \"''\", 'a', 'period', 'when', 'interest', 'in', 'AI', 'dropped', '.', 'In', 'the', '1980s', ',', 'AI', 'became', 'popular', 'again', 'because', 'of', 'expert', 'systems—programs', 'that', 'could', 'make', 'decisions', 'like', 'a', 'human', 'expert', '.', 'But', 'these', 'systems', 'were', 'expensive', 'and', 'hard', 'to', 'maintain', ',', 'which', 'caused', 'another', 'decline', 'in', 'the', '1990s', '.', 'AI', 'came', 'back', 'strong', 'in', 'the', '2000s', 'with', 'the', 'rise', 'of', 'machine', 'learning', '.', 'Computers', 'started', 'learning', 'from', 'data', 'instead', 'of', 'just', 'following', 'rules', '.', 'In', '1997', ',', 'IBM', \"'s\", 'Deep', 'Blue', 'beat', 'the', 'world', 'chess', 'champion', '.', 'In', '2012', ',', 'deep', 'learning', 'took', 'off', 'when', 'a', 'program', 'called', 'AlexNet', 'beat', 'others', 'in', 'an', 'image', 'recognition', 'contest', '.', 'Since', 'then', ',', 'AI', 'has', 'improved', 'rapidly', '.', 'Tools', 'like', 'Siri', ',', 'Google', 'Assistant', ',', 'and', 'self-driving', 'cars', 'all', 'use', 'AI', '.', 'In', '2016', ',', 'AlphaGo', 'beat', 'a', 'top', 'human', 'player', 'in', 'the', 'game', 'of', 'Go', '.', 'In', '2020', ',', 'language', 'models', 'like', 'GPT-3', 'could', 'write', 'essays', ',', 'answer', 'questions', ',', 'and', 'hold', 'conversations', '.', 'Today', ',', 'AI', 'is', 'everywhere—from', 'hospitals', 'and', 'schools', 'to', 'phones', 'and', 'factories', '.', 'While', 'it', 'brings', 'many', 'benefits', ',', 'it', 'also', 'raises', 'concerns', 'about', 'jobs', ',', 'fairness', ',', 'and', 'safety', '.', 'That', '’', 's', 'why', 'governments', 'and', 'researchers', 'are', 'working', 'on', 'rules', 'to', 'use', 'AI', 'responsibly', '.']\n",
      "Total number of stems 244\n",
      "Filtered ['Artificial', 'Intelligence', '(', 'AI', ')', 'roots', 'ancient', 'times', 'people', 'imagined', 'machines', 'statues', 'could', 'think', 'act', 'like', 'humans', '.', 'Philosophers', 'like', 'Aristotle', 'laid', 'groundwork', 'studying', 'logic', 'reasoning', '.', '1950s', ',', 'scientists', 'began', 'building', 'real', 'machines', 'could', 'solve', 'problems', '.', '1956', ',', 'group', 'researchers', 'held', 'conference', 'Dartmouth', 'College', 'officially', 'named', 'field', '“', 'Artificial', 'Intelligence.', '”', 'believed', 'machines', 'could', 'learn', 'think', 'like', 'humans', '.', '1960s', '70s', ',', 'AI', 'research', 'made', 'progress', '.', 'Computers', 'could', 'play', 'games', 'like', 'chess', 'solve', 'math', 'problems', '.', 'soon', ',', 'people', 'realized', 'technology', '’', 'advanced', 'enough', ',', 'funding', 'cut', '.', 'led', 'first', '``', 'AI', 'winter', ',', \"''\", 'period', 'interest', 'AI', 'dropped', '.', '1980s', ',', 'AI', 'became', 'popular', 'expert', 'systems—programs', 'could', 'make', 'decisions', 'like', 'human', 'expert', '.', 'systems', 'expensive', 'hard', 'maintain', ',', 'caused', 'another', 'decline', '1990s', '.', 'AI', 'came', 'back', 'strong', '2000s', 'rise', 'machine', 'learning', '.', 'Computers', 'started', 'learning', 'data', 'instead', 'following', 'rules', '.', '1997', ',', 'IBM', \"'s\", 'Deep', 'Blue', 'beat', 'world', 'chess', 'champion', '.', '2012', ',', 'deep', 'learning', 'took', 'program', 'called', 'AlexNet', 'beat', 'others', 'image', 'recognition', 'contest', '.', 'Since', ',', 'AI', 'improved', 'rapidly', '.', 'Tools', 'like', 'Siri', ',', 'Google', 'Assistant', ',', 'self-driving', 'cars', 'use', 'AI', '.', '2016', ',', 'AlphaGo', 'beat', 'top', 'human', 'player', 'game', 'Go', '.', '2020', ',', 'language', 'models', 'like', 'GPT-3', 'could', 'write', 'essays', ',', 'answer', 'questions', ',', 'hold', 'conversations', '.', 'Today', ',', 'AI', 'everywhere—from', 'hospitals', 'schools', 'phones', 'factories', '.', 'brings', 'many', 'benefits', ',', 'also', 'raises', 'concerns', 'jobs', ',', 'fairness', ',', 'safety', '.', '’', 'governments', 'researchers', 'working', 'rules', 'use', 'AI', 'responsibly', '.']\n",
      "stems: ['artifici', 'intellig', '(', 'ai', ')', 'root', 'ancient', 'time', 'peopl', 'imagin', 'machin', 'statu', 'could', 'think', 'act', 'like', 'human', '.', 'philosoph', 'like', 'aristotl', 'laid', 'groundwork', 'studi', 'logic', 'reason', '.', '1950', ',', 'scientist', 'began', 'build', 'real', 'machin', 'could', 'solv', 'problem', '.', '1956', ',', 'group', 'research', 'held', 'confer', 'dartmouth', 'colleg', 'offici', 'name', 'field', '“', 'artifici', 'intelligence.', '”', 'believ', 'machin', 'could', 'learn', 'think', 'like', 'human', '.', '1960', '70', ',', 'ai', 'research', 'made', 'progress', '.', 'comput', 'could', 'play', 'game', 'like', 'chess', 'solv', 'math', 'problem', '.', 'soon', ',', 'peopl', 'realiz', 'technolog', '’', 'advanc', 'enough', ',', 'fund', 'cut', '.', 'led', 'first', '``', 'ai', 'winter', ',', \"''\", 'period', 'interest', 'ai', 'drop', '.', '1980', ',', 'ai', 'becam', 'popular', 'expert', 'systems—program', 'could', 'make', 'decis', 'like', 'human', 'expert', '.', 'system', 'expens', 'hard', 'maintain', ',', 'caus', 'anoth', 'declin', '1990', '.', 'ai', 'came', 'back', 'strong', '2000', 'rise', 'machin', 'learn', '.', 'comput', 'start', 'learn', 'data', 'instead', 'follow', 'rule', '.', '1997', ',', 'ibm', \"'s\", 'deep', 'blue', 'beat', 'world', 'chess', 'champion', '.', '2012', ',', 'deep', 'learn', 'took', 'program', 'call', 'alexnet', 'beat', 'other', 'imag', 'recognit', 'contest', '.', 'sinc', ',', 'ai', 'improv', 'rapidli', '.', 'tool', 'like', 'siri', ',', 'googl', 'assist', ',', 'self-driv', 'car', 'use', 'ai', '.', '2016', ',', 'alphago', 'beat', 'top', 'human', 'player', 'game', 'go', '.', '2020', ',', 'languag', 'model', 'like', 'gpt-3', 'could', 'write', 'essay', ',', 'answer', 'question', ',', 'hold', 'convers', '.', 'today', ',', 'ai', 'everywhere—from', 'hospit', 'school', 'phone', 'factori', '.', 'bring', 'mani', 'benefit', ',', 'also', 'rais', 'concern', 'job', ',', 'fair', ',', 'safeti', '.', '’', 'govern', 'research', 'work', 'rule', 'use', 'ai', 'respons', '.']\n",
      "Total Number of Lema 2\n",
      "Lemmas: ['Artificial', 'Intelligence', '(', 'AI', ')', 'root', 'ancient', 'time', 'people', 'imagined', 'machine', 'statue', 'could', 'think', 'act', 'like', 'human', '.', 'Philosophers', 'like', 'Aristotle', 'laid', 'groundwork', 'studying', 'logic', 'reasoning', '.', '1950s', ',', 'scientist', 'began', 'building', 'real', 'machine', 'could', 'solve', 'problem', '.', '1956', ',', 'group', 'researcher', 'held', 'conference', 'Dartmouth', 'College', 'officially', 'named', 'field', '“', 'Artificial', 'Intelligence.', '”', 'believed', 'machine', 'could', 'learn', 'think', 'like', 'human', '.', '1960s', '70', ',', 'AI', 'research', 'made', 'progress', '.', 'Computers', 'could', 'play', 'game', 'like', 'chess', 'solve', 'math', 'problem', '.', 'soon', ',', 'people', 'realized', 'technology', '’', 'advanced', 'enough', ',', 'funding', 'cut', '.', 'led', 'first', '``', 'AI', 'winter', ',', \"''\", 'period', 'interest', 'AI', 'dropped', '.', '1980s', ',', 'AI', 'became', 'popular', 'expert', 'systems—programs', 'could', 'make', 'decision', 'like', 'human', 'expert', '.', 'system', 'expensive', 'hard', 'maintain', ',', 'caused', 'another', 'decline', '1990s', '.', 'AI', 'came', 'back', 'strong', '2000s', 'rise', 'machine', 'learning', '.', 'Computers', 'started', 'learning', 'data', 'instead', 'following', 'rule', '.', '1997', ',', 'IBM', \"'s\", 'Deep', 'Blue', 'beat', 'world', 'chess', 'champion', '.', '2012', ',', 'deep', 'learning', 'took', 'program', 'called', 'AlexNet', 'beat', 'others', 'image', 'recognition', 'contest', '.', 'Since', ',', 'AI', 'improved', 'rapidly', '.', 'Tools', 'like', 'Siri', ',', 'Google', 'Assistant', ',', 'self-driving', 'car', 'use', 'AI', '.', '2016', ',', 'AlphaGo', 'beat', 'top', 'human', 'player', 'game', 'Go', '.', '2020', ',', 'language', 'model', 'like', 'GPT-3', 'could', 'write', 'essay', ',', 'answer', 'question', ',', 'hold', 'conversation', '.', 'Today', ',', 'AI', 'everywhere—from', 'hospital', 'school', 'phone', 'factory', '.', 'brings', 'many', 'benefit', ',', 'also', 'raise', 'concern', 'job', ',', 'fairness', ',', 'safety', '.', '’', 'government', 'researcher', 'working', 'rule', 'use', 'AI', 'responsibly', '.']\n",
      "POS Tags [('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('roots', 'VBP'), ('ancient', 'JJ'), ('times', 'NNS'), ('people', 'NNS'), ('imagined', 'JJ'), ('machines', 'NNS'), ('statues', 'NNS'), ('could', 'MD'), ('think', 'VB'), ('act', 'IN'), ('like', 'IN'), ('humans', 'NNS'), ('.', '.'), ('Philosophers', 'NNS'), ('like', 'IN'), ('Aristotle', 'NNP'), ('laid', 'VBD'), ('groundwork', 'NN'), ('studying', 'VBG'), ('logic', 'JJ'), ('reasoning', 'NN'), ('.', '.'), ('1950s', 'CD'), (',', ','), ('scientists', 'NNS'), ('began', 'VBD'), ('building', 'VBG'), ('real', 'JJ'), ('machines', 'NNS'), ('could', 'MD'), ('solve', 'VB'), ('problems', 'NNS'), ('.', '.'), ('1956', 'CD'), (',', ','), ('group', 'NN'), ('researchers', 'NNS'), ('held', 'VBD'), ('conference', 'NN'), ('Dartmouth', 'NNP'), ('College', 'NNP'), ('officially', 'RB'), ('named', 'VBD'), ('field', 'NN'), ('“', 'NNP'), ('Artificial', 'NNP'), ('Intelligence.', 'NNP'), ('”', 'NNP'), ('believed', 'VBD'), ('machines', 'NNS'), ('could', 'MD'), ('learn', 'VB'), ('think', 'VB'), ('like', 'IN'), ('humans', 'NNS'), ('.', '.'), ('1960s', 'CD'), ('70s', 'CD'), (',', ','), ('AI', 'NNP'), ('research', 'NN'), ('made', 'VBD'), ('progress', 'NN'), ('.', '.'), ('Computers', 'NNS'), ('could', 'MD'), ('play', 'VB'), ('games', 'NNS'), ('like', 'IN'), ('chess', 'NN'), ('solve', 'VBP'), ('math', 'NN'), ('problems', 'NNS'), ('.', '.'), ('soon', 'RB'), (',', ','), ('people', 'NNS'), ('realized', 'VBD'), ('technology', 'NN'), ('’', 'NNP'), ('advanced', 'VBD'), ('enough', 'RB'), (',', ','), ('funding', 'VBG'), ('cut', 'NN'), ('.', '.'), ('led', 'VBN'), ('first', 'JJ'), ('``', '``'), ('AI', 'NNP'), ('winter', 'NN'), (',', ','), (\"''\", \"''\"), ('period', 'NN'), ('interest', 'NN'), ('AI', 'NNP'), ('dropped', 'VBD'), ('.', '.'), ('1980s', 'CD'), (',', ','), ('AI', 'NNP'), ('became', 'VBD'), ('popular', 'JJ'), ('expert', 'NN'), ('systems—programs', 'NNS'), ('could', 'MD'), ('make', 'VB'), ('decisions', 'NNS'), ('like', 'IN'), ('human', 'JJ'), ('expert', 'NN'), ('.', '.'), ('systems', 'NNS'), ('expensive', 'JJ'), ('hard', 'JJ'), ('maintain', 'NN'), (',', ','), ('caused', 'VBD'), ('another', 'DT'), ('decline', 'NN'), ('1990s', 'CD'), ('.', '.'), ('AI', 'NNP'), ('came', 'VBD'), ('back', 'RB'), ('strong', 'JJ'), ('2000s', 'CD'), ('rise', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.'), ('Computers', 'NNS'), ('started', 'VBD'), ('learning', 'VBG'), ('data', 'NNS'), ('instead', 'RB'), ('following', 'VBG'), ('rules', 'NNS'), ('.', '.'), ('1997', 'CD'), (',', ','), ('IBM', 'NNP'), (\"'s\", 'POS'), ('Deep', 'NNP'), ('Blue', 'NNP'), ('beat', 'VBD'), ('world', 'NN'), ('chess', 'NN'), ('champion', 'NN'), ('.', '.'), ('2012', 'CD'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), ('took', 'VBD'), ('program', 'NN'), ('called', 'VBN'), ('AlexNet', 'NNP'), ('beat', 'NN'), ('others', 'NNS'), ('image', 'NN'), ('recognition', 'NN'), ('contest', 'NN'), ('.', '.'), ('Since', 'IN'), (',', ','), ('AI', 'NNP'), ('improved', 'VBD'), ('rapidly', 'RB'), ('.', '.'), ('Tools', 'NNS'), ('like', 'IN'), ('Siri', 'NNP'), (',', ','), ('Google', 'NNP'), ('Assistant', 'NNP'), (',', ','), ('self-driving', 'JJ'), ('cars', 'NNS'), ('use', 'VBP'), ('AI', 'NNP'), ('.', '.'), ('2016', 'CD'), (',', ','), ('AlphaGo', 'NNP'), ('beat', 'VBD'), ('top', 'JJ'), ('human', 'NN'), ('player', 'NN'), ('game', 'NN'), ('Go', 'NNP'), ('.', '.'), ('2020', 'CD'), (',', ','), ('language', 'NN'), ('models', 'NNS'), ('like', 'IN'), ('GPT-3', 'NNP'), ('could', 'MD'), ('write', 'VB'), ('essays', 'NNS'), (',', ','), ('answer', 'JJR'), ('questions', 'NNS'), (',', ','), ('hold', 'JJ'), ('conversations', 'NNS'), ('.', '.'), ('Today', 'NN'), (',', ','), ('AI', 'NNP'), ('everywhere—from', 'VBP'), ('hospitals', 'NNS'), ('schools', 'NNS'), ('phones', 'NNS'), ('factories', 'NNS'), ('.', '.'), ('brings', 'VBZ'), ('many', 'JJ'), ('benefits', 'NNS'), (',', ','), ('also', 'RB'), ('raises', 'VBZ'), ('concerns', 'NNS'), ('jobs', 'NNS'), (',', ','), ('fairness', 'NN'), (',', ','), ('safety', 'NN'), ('.', '.'), ('’', 'JJ'), ('governments', 'NNS'), ('researchers', 'NNS'), ('working', 'VBG'), ('rules', 'NNS'), ('use', 'VBP'), ('AI', 'NNP'), ('responsibly', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "text=input(\"Enter the Text\")\n",
    "#Tokenization\n",
    "tokens=word_tokenize(text)\n",
    "#STopword removal\n",
    "stop_words =set(stopwords.words('english'))\n",
    "print(\"Stop Words\",stop_words)\n",
    "s=0\n",
    "filtered=[]\n",
    "for w in tokens:\n",
    "    s=s+1\n",
    "    if w.lower()not in stop_words:\n",
    "        filtered.append(w)\n",
    "        #stemming\n",
    "stemmer=PorterStemmer()\n",
    "stems=[]\n",
    "ss=0\n",
    "for word in filtered:\n",
    "    ss=ss+1\n",
    "    stemmed_word=stemmer.stem(word)\n",
    "    stems.append(stemmed_word)\n",
    "    #lemmatization\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "lemmas=[]\n",
    "l=0\n",
    "for word in filtered:\n",
    "    l=1+1\n",
    "    lemmas.append(lemmatizer.lemmatize(word))\n",
    "    # pos taggging\n",
    "pos_tags=pos_tag(filtered)\n",
    "print(\"Total number of Tokens\",s)\n",
    "print(\"Tokens:\",tokens)\n",
    "print(\"Total number of stems\",ss)\n",
    "print(\"Filtered\",filtered)\n",
    "print(\"stems:\",stems)\n",
    "print(\"Total Number of Lema\",l)\n",
    "print(\"Lemmas:\",lemmas)\n",
    "print(\"POS Tags\",pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72e279-443c-457f-b6a7-aff065eec50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
